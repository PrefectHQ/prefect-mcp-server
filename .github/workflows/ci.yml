name: CI

env:
  # Enable colored output
  PY_COLORS: 1

on:
  push:
    branches: ["main"]
    paths:
      - "evals/**/*.py"
      - "src/**"
      - "tests/**"
      - "uv.lock"
      - "pyproject.toml"
      - ".github/workflows/**"

  pull_request:
    paths:
      - "evals/**/*.py"
      - "src/**"
      - "tests/**"
      - "uv.lock"
      - "pyproject.toml"
      - ".github/workflows/**"

  workflow_dispatch:

permissions:
  contents: read

jobs:
  test:
    name: "test: python ${{ matrix.python-version }} on ${{ matrix.os }}"
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.13"]
      fail-fast: false
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"
          python-version: ${{ matrix.python-version }}

      - uses: extractions/setup-just@v3

      - name: Run tests
        run: just test

  evals:
    runs-on: ubuntu-latest

    timeout-minutes: 10

    permissions:
      contents: read
      pull-requests: write
      checks: write

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"
          python-version: "3.12"

      - uses: extractions/setup-just@v3

      - name: Post Logfire Link
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const sha = context.payload.pull_request.head.sha;
            const serviceName = 'prefect-mcp-server-evals';

            // Get current time and 15 minutes later
            const now = new Date();
            const later = new Date(now.getTime() + 15 * 60 * 1000);

            // Format as ISO strings and encode for URL
            const since = encodeURIComponent(now.toISOString());
            const until = encodeURIComponent(later.toISOString());

            const logfireUrl = `https://logfire-us.pydantic.dev/prefect/prefect-mcp-server?env=ci&service=${serviceName}&version=${sha}&since=${since}&until=${until}`;

            const comment = `## üìä Observability

            View eval run traces in Logfire: [${serviceName} @ ${sha.substring(0, 7)}](${logfireUrl})`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Observability')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Run evals
        id: run_evals
        continue-on-error: true
        run: |
          uv run --frozen pytest evals --junit-xml=evals-results.xml --tb=short
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          LOGFIRE_TOKEN: ${{ secrets.LOGFIRE_TOKEN }}
          ENVIRONMENT: ci
          LOGFIRE_SERVICE_NAME: prefect-mcp-server-evals
          LOGFIRE_SERVICE_VERSION: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Upload eval results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: eval-results
          path: evals-results.xml

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            evals-results.xml
          check_name: Evaluation Results
          comment_mode: always
          fail_on: nothing

      - name: Beautify evaluation results comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const issue_number = context.issue.number;

            const { data: comments } = await github.rest.issues.listComments({
              owner,
              repo,
              issue_number,
              per_page: 100,
            });

            const target = comments.find(
              (comment) =>
                comment.user?.login === 'github-actions[bot]' &&
                comment.body?.startsWith('## Evaluation Results')
            );

            if (!target) {
              core.info('Evaluation Results comment not found.');
              return;
            }

            const body = target.body ?? '';
            const headerEnd = body.indexOf('\n\n');
            const restStart = body.indexOf('\n\nFor more details');

            if (headerEnd === -1 || restStart === -1 || restStart <= headerEnd) {
              core.info('Comment format not recognized; skipping beautify.');
              return;
            }

            const header = body.slice(0, headerEnd);
            const metricsBlock = body.slice(headerEnd + 2, restStart);

            if (metricsBlock.includes('| Tests |')) {
              core.info('Comment already formatted; skipping.');
              return;
            }

            const extract = (pattern) => {
              const match = metricsBlock.match(pattern);
              return match ? match[1].trim() : null;
            };

            const tests = extract(/(\d+)\s+tests?/i);
            const passed = extract(/(\d+)\s+‚úÖ/);
            const failures = extract(/(\d+)\s+‚ùå/);
            const errors = extract(/(\d+)\s+üî•/);
            const skipped = extract(/(\d+)\s+üò¥/);
            const suites = extract(/(\d+)\s+suites?/i);
            const files = extract(/(\d+)\s+files?/i);
            const duration = extract(/([0-9hms.,\s]+?)\s*‚è±Ô∏è/i);

            if (!tests) {
              core.info('Unable to extract test count; skipping beautify.');
              return;
            }

            const withEmoji = (value, emoji) => {
              if (!value) {
                return '‚Äî';
              }
              return emoji ? `${value} ${emoji}` : value;
            };

            const durationCell = duration ? `${duration} ‚è±Ô∏è` : '‚Äî';
            const table = [
              '| Tests | Passed | Failed | Errors | Skipped | Duration | Suites | Files |',
              '| ---: | ---: | ---: | ---: | ---: | --- | ---: | ---: |',
              `| ${tests} | ${withEmoji(passed, '‚úÖ')} | ${withEmoji(failures, '‚ùå')} | ${withEmoji(errors, 'üî•')} | ${withEmoji(skipped, 'üò¥')} | ${durationCell} | ${suites ?? '‚Äî'} | ${files ?? '‚Äî'} |`,
              '',
            ].join('\n');

            let rest = body.slice(restStart);
            rest = rest.replace(/^\n+/, '\n\n');
            const newBody = `${header}\n\n${table}${rest}`;

            if (newBody === body) {
              core.info('No changes needed.');
              return;
            }

            await github.rest.issues.updateComment({
              owner,
              repo,
              comment_id: target.id,
              body: newBody,
            });

  lint:
    timeout-minutes: 2

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Run pre-commit
        run: uv run pre-commit run --all-files
        env:
          SKIP: no-commit-to-branch
